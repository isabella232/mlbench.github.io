---
layout: post
title: Tutorial
author: r_grubenmann
published: true
tags: [tutorial,guide,google cloud,setup]
excerpt_separator: <!--more-->
---
This tutorial guides you through setting up MLBench in a Google Cloud [Kubernetes Engine](https://cloud.google.com/kubernetes-engine/) cluster and explains basic MLBench functionality. For setup in other environments, please refer to our [installation documentation](https://mlbench.readthedocs.io/en/latest/installation.html)

<!--more-->

**Please beware any costs that might be incurred by running this tutorial on the Google cloud. Usually costs should only be on the order of 5-10USD. We don't take any responsibility costs incurred**

### Prerequisites

This tutorial assumes you have a Google Cloud account with permissions to create a new cluster.
You also need to have [Python](https://www.python.org/), [Git](https://git-scm.com/), and [Docker](https://www.docker.com) installed locally and the Docker Daemon should be running.

Now you have to checkout the mlbench github repository and have a terminal open in the checked-out mlbench directory.

```shell
$ git clone git@github.com:mlbench/mlbench.git
```

Enter the newly created directory

```shell
$ cd mlbench
```

### Setting up gcloud client

Follow the steps detailed [here](https://cloud.google.com/sdk/docs/quickstarts) to install the Google Cloud SDK.

Now install the [kubectl](https://kubernetes.io/docs/reference/kubectl/overview/) tool with the Google configuration. kubectl is a command line interface for communicating with a Kubernetes API server. 

```shell
$ gcloud components install kubectl
```

This will configure the kubernetes kubectl with the correct credentials for your account.

We can now create a Kubernetes cluster called ``mlbench`` by running

```shell
$ gcloud container clusters create mlbench --machine-type='n1-standard-2'
```
By default, this will create a new cluster with 3 nodes, all of which are ``n1-standard-2`` instances.
Once the cluster is created, we need to set the correct credentials for kubectl

```shell
$ gcloud container clusters get-credentials mlbench
```

This sets the default context of kubectl to our newly created cluster.

### Installing Helm

[Helm](https://github.com/helm/helm/) is a package manager for Kubernetes applications. It helps install pre-defined distributed applications to clusters.

To install helm, run

```shell
$ curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash
```

For helm to work properly, it needs a service account in the cluster with ``cluster-admin`` rights. We can set up an account with the correct privileges by running

```shell
$ kubectl --namespace kube-system create sa tiller
$ kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
```

This creates a new service account with the correct privileges for the helm server component ``tiller``, which takes care of managing the deployment of pods to our cluster.

We can now initialize helm with our newly created service account

```shell
$ helm init --service-account tiller
```

After this, helm is set up and ready to deploy applications to our newly created cluster.

### Building the Master and Worker images

*Note: You can skip this part if you want to use the precompiled docker images*

To use custom images, we will have to host them in a docker registry. The [Google Cloud Container Registry](https://cloud.google.com/container-registry/) is an obvious choice for Google Cloud.

First we need to enable access to it on our commandline

```shell
$ gcloud auth configure-docker
```

We provide easy to use commands to build and deploy the images using ```make```. Make sure to correctly set the name of your Google Cloud project (``<gcloud project name>``) in the following commands

```shell
$ make publish-docker component=master docker_registry=gcr.io/<gcloud project name>
$ make publish-docker component=worker docker_registry=gcr.io/<gcloud project name>
```

This will build the ``master`` and ``worker`` docker images and push them to the Container Registry.

### Installing MLBench

Now copy the file `charts/mlbench/values.yaml` to the current directory, calling it `myvalues.yaml`.

```shell
$ cp charts/mlbench/values.yaml myvalues.yaml
```

This file contains default values for most settings in mlbench. There are however some you need to set yourself to reasonable values for your cluster, namely:

```yaml
limits:
  cpu: 1000m
  gpu: 0
  maximumWorkers: 3
  bandwidth: 1000
```

This limits the maximum usable resources (And the maximum you are able to chose in the UI) to 1 CPU core , 0 GPUs, 1000 mbit/s network speed per node and 3 nodes total.

*Note: Our ``n1-standard-2`` instances have 2 CPU cores. But due to Google Cloud Kubernetes running its own monitoring and management pods, which also use some CPU, it is advisable to set MLBench to use one core less than available*

If you followed the previous section and built the docker images yourself, your ``myvalues.yaml`` file should look as follows (again, replace ``<gcloud project name>`` with your Google Cloud project name)

```yaml
master:
  image:
    repository: gcr.io/<gcloud project name>/mlbench_master
    tag: latest
    pullPolicy: Always


worker:
  image:
    repository: gcr.io/<gcloud project name>/mlbench_worker
    tag: latest
    pullPolicy: Always

limits:
  cpu: 1000m
  gpu: 0
  maximumWorkers: 3
  bandwidth: 1000
```

Now it is time to install MLBench

```shell
$ helm upgrade --wait --recreate-pods -f myvalues.yaml --timeout 900 --install release1 charts/mlbench
```

This creates Kubernetes templates based on the values set in ``myvalues.yaml`` and installs them to our Kubernetes cluster, calling the release ``release1``.

*Note: Release names allow you to install multiple instances of the same helm chart side by side, but are not relevant for this tutorial*

Since the deployment is not open to the internet by default, the default instructions printed by the previous command **do not apply**.
To gain access to MLBench, we need to add a firewall rule to Google Cloud

```shell
$ export NODE_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[0].nodePort}" services ${RELEASE_NAME}-mlbench-master)
$ export NODE_IP=$(gcloud compute instances list|grep $(kubectl get nodes --namespace default -o jsonpath="{.items[0].status.addresses[0].address}") |awk '{print $5}')
$ gcloud compute firewall-rules create --quiet mlbench --allow tcp:$NODE_PORT,tcp:$NODE_PORT
```

This gets the public ip of the node the ``master`` image is deployed on, plus the randomly selected port it is running on, and adds a firewall rule allowing access to that port.

To get the URL the dashboard is accessible under, we can now just run

```shell
$ echo http://$NODE_IP:$NODE_PORT
http://172.16.0.1:32145
```

and it should print the URL (In this example it printed ``http://172.16.0.1:32145``)

Simply open the URL in your browser and you should be ready to go.

### Using MLBench
Once you open the dashboard URL, you will be greeted by a screen similar to this

<a href="{{ site.baseurl }}public/images/Dashboard_Index.png" data-lightbox="Dashboard_Index" data-title="The MLBench Dashboard">
  <img src="{{ site.baseurl }}public/images/Dashboard_Index.png" alt="The MLBench Dashboard" style="max-width:80%;"/>
</a>

This shows you all currently used worker nodes (2 by default) and their current state and resource usage.
Changes to the workers are continuously monitored and updated.

Clicking on the name of a worker will open up a more detailed view of its resource usage.

<a href="{{ site.baseurl }}public/images/Worker_Details.png" data-lightbox="Worker_Detail" data-title="Detailed Resource Usage of a Worker">
  <img src="{{ site.baseurl }}public/images/Worker_Details.png" alt="Detailed Resource Usage of a Worker" style="max-width:80%;"/>
</a>

The ``Runs`` page in the menu on the left allows you to start new experiments as well as view already started experiments.

When adding a run, you can chose a name for this particular run, the number of worker nodes to utilize, as well as resource constraints for the individual workers.

*Note: In the future, you will also be able to chose different models/frameworks/etc. but this is not yet implemented at the time this tutorial was written. By default, Resnet-18 is run.*

<a href="{{ site.baseurl }}public/images/Create_Run.png" data-lightbox="Create_Run" data-title="Starting a new Experiment">
  <img src="{{ site.baseurl }}public/images/Create_Run.png" alt="Starting a new Experiment" style="max-width:80%;"/>
</a>

When you start a new run, MLBench will automatically rescale the worker StatefulSet it Kubernetes and apply any resource limitations you might have set. It will then start training the distributed machine learning model.

You can then see the details of the experiment by clicking on its entry in the list of experiment. You can see the ``stdout`` and ``stderr`` of all workers, as well as any performance metrics the workers send back to the dashboard (e.g. Training Accuracy,  Training Loss). You can also download all collected metrics as json files (Including resource usage of individual workers during the experiment).

*Note: You can download metrics at any point during a run. But only the values available up until that point will be downloaded. If no metrics are available yet, the download will be empty*

<a href="{{ site.baseurl }}public/images/Run_Stdout.png" data-lightbox="Run" data-title="Stdout of an experiment">
  <img src="{{ site.baseurl }}public/images/Run_Stdout.png" alt="Stdout of an experiment" style="max-width:80%;"/>
</a>

<a href="{{ site.baseurl }}public/images/Run_Loss.png" data-lightbox="Run" data-title="Training Loss curve of an experiment">
  <img src="{{ site.baseurl }}public/images/Run_Loss.png" alt="Training Loss curve of an experiment" style="max-width:80%;"/>
</a>

That's it! You successfully ran an distributed machine learning algorithm in the cloud. You can also easily develop custom worker images for your own models and compare them to existing benchmarking code without a lot of overhead.

### Appendix 1: Run mlbench on GKE

The previous commands can be summarized as follows

{% gist 23361aea5fe252570496acc7da4fb599 %}

Customize environment variables like `NUM_NODES` and run the scripts with `create`, `install` and `dashboard` sequantially. The last command will give you the external ip of the dashboard. When the job is done, run this script with `cleanup` to delete everything.

### Appendix 2: Use NFS for Data storage
To avoid downloading datasets everytime we reinstall mlbench, we can use a persistent disk to save the data. To do so, one can create a GCE disk like
```bash
gcloud compute disks create --size=10G --zone=europe-west1-b my-pd-name
```
and add the name of persistent disk to `myvalues.yaml`
```yaml
gcePersistentDisk:
  enabled: True
  pdName: my-pd-name
```
Note that Kubernetes resources `PersistentVolume` and `PersistentVolumeClaim` will be deleted when we delete the helm chart, but the datasets will be persisted on the GCE disk.